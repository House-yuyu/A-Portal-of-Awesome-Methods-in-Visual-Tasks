<p align="center">
  <h1 align="center">A Portal of Awesome Methods in Visual Tasks</h1>

This GitHub repository summarizes papers and projects related to the low-level vision tasks, AIGC, etc. 

If you have any suggestions about this repository, please feel free to [start a new issue](https://github.com/House-yuyu/A-Portal-of-Awesome-Methods-in-Visual-Tasks/issues/new) or [pull requests](https://github.com/House-yuyu/A-Portal-of-Awesome-Methods-in-Visual-Tasks/pulls).

<!-- omit in toc -->
# üî•News
- [Mar. 7th] **CVPR 2024, AAAI 2024, ICLR 2024 papers are updated.** Note that papers are not available currently are highlighted with "‚ö†Ô∏è". PDFs and references will be updated as soon as they are released.

<!-- omit in toc -->
# <span id="contents">Contents</span>
- [To-Do Lists](#to-do-lists)
- [Papers](#papers) _(Mainly Deep Learning-Based)_
  - [üî•Text-Guided Image Inpainting](#üî•-text-guided-image-inpainting)
    - [Year 2024](#text-year-2024)
    - [Year 2023](#text-year-2023)
    - [Year 2022](#text-year-2022)
    - [Year 2021](#text-year-2021)
    - [Year 2020](#text-year-2020)
  - [Vanilla Image Inpainting](#vanilla-image-inpainting)
    - [Year 2024](#vanilla-year-2024)
    - [Year 2023](#vanilla-year-2023)
    - [Year 2022](#vanilla-year-2022)
    - [Year 2021](#vanilla-year-2021)
    - [Year 2020](#vanilla-year-2020)
    - [Year 2019](#vanilla-year-2019)
    - [Year 2018](#vanilla-year-2018)
    - [Year 2017](#vanilla-year-2017)
    - [Year 2016](#vanilla-year-2016)
  - [Blind Image Inpainting](#blind-image-inpainting)
    - [Year 2023](#blind-year-2023)
    - [Year 2022](#blind-year-2022)
    - [Year 2020](#blind-year-2020)
  - [Edge-Based Image Inpainting](#edge-based-image-inpainting)
    - [Year 2023](#edge-year-2023)
    - [Year 2022](#edge-year-2022)
    - [Year 2021](#edge-year-2021)
    - [Year 2019](#edge-year-2019)
  - [Sketch-Guided Image Inpainting](#sketch-guided-image-inpainting)
    - [Year 2023](#sketch-year-2023)
    - [Year 2022](#sketch-year-2022)
    - [Year 2021](#sketch-year-2021)
    - [Year 2019](#sketch-year-2019)
  - [Face Image Inpainting](#face-image-inpainting)
    - [Year 2023](#face-year-2023)
    - [Year 2021](#face-year-2021)
    - [Year 2020](#face-year-2020)
    - [Year 2017](#face-year-2017)
  - [Fashion Image Inpainting](#fashion-image-inpainting)
    - [Year 2020](#fashion-year-2020)
    - [Year 2019](#fashion-year-2019)
  - [Conventional Methods](#conventional-methods) _(Non Deep Learning-Based)_
      - [Year 2020](#conventional-year-2020)
      - [Year 2019](#conventional-year-2019)
      - [Year 2018](#conventional-year-2018)
      - [Year 2016](#conventional-year-2016)
      - [Year 2011](#conventional-year-2011)
      - [Year 2005](#conventional-year-2005)
      - [Year 2004](#conventional-year-2004)
      - [Year 2000](#conventional-year-2000)
- [Survey Papers](#survey-papers)
- [Datasets](#datasets)
- [Q&A](#qa)
- [References](#references)
- [Star History](#star-history)

<!-- omit in toc -->
# To-Do Lists
- Recent Papers
  - [x] Update CVPR 2024 Papers
  - [x] Update AAAI 2024 Papers
    - [ ] Update PDFs and References
  - [x] Update ICLR 2024 Papers
  - [ ] Update NeurIPS 2024 Papers
  - Regular Maintenance of Preprint arXiv Papers and Missed Papers
- Previous Papers
  - Published Papers on Conferences
    - [x] Update CVPR papers
    - [x] Update CVPRW papers
    - [x] Update ICCV papers
    - [x] Update ICCVW papers
    - [x] Update ECCV papers
    - [x] Update AAAI papers
    - [x] Update IJCAI papers
    - [x] Update ACM MM papers
    - [x] Update WACV papers
    - [x] Update NeurIPS papers
    - [x] Update ICLR papers
  - Published Papers on Journals
    - [x] Update TMM papers
    - [x] Update TIP papers 
    - [x] Update TPAMI papers
    - [x] Update TCSVT papers

[<u><small><üéØBack to Top></small></u>](#contents)


[<u><üéØBack to Top></u>](#head-content)

* <span id="head-si"> **Text-to-Imageü§î**  </span> 
    * (arXiv preprint 2024) [üí¨ Gender Bias Alignment] **PopAlign: Population-Level Alignment for Fair Text-to-Image Generation**, Shufan Li et al.  [[Paper](https://arxiv.org/abs/2406.19668)] [[Code](https://github.com/jacklishufan/PopAlignSDXL)]
    * (arXiv preprint 2024) [üí¨ Fine-Grained Feedback] **Beyond Thumbs Up/Down: Untangling Challenges of Fine-Grained Feedback for Text-to-Image Generation**, Katherine M. Collins et al.  [[Paper](https://arxiv.org/abs/2406.16807)] 
    * (CVPR 2024-Best Paper) [üí¨ Human Feedback] **Rich Human Feedback for Text-to-Image Generation**, Youwei Liang et al.  [[Paper](https://arxiv.org/abs/2312.10240)] 
    * (ICLR 2024) [üí¨ Unauthorized Data] **DIAGNOSIS: Detecting Unauthorized Data Usages in Text-to-image Diffusion Models**, Zhenting Wang et al.  [[Paper](https://openreview.net/pdf?id=f8S3aLm0Vp)] [[Code](https://github.com/ZhentingWang/DIAGNOSIS)]
    * (CVPR 2024) [üí¨ Open-set Bias Detection] **OpenBias: Open-set Bias Detection in Text-to-Image Generative Models**, Moreno D'Inc√† et al.  [[Paper](https://arxiv.org/abs/2404.07990)] 
    * (arXiv preprint 2024) [üí¨ Spatial Consistency] **Getting it Right: Improving Spatial Consistency in Text-to-Image Models**, Agneet Chatterjee et al.  [[Paper](https://arxiv.org/abs/2404.01197)] [[Project](https://spright-t2i.github.io/)] [[Code](https://github.com/SPRIGHT-T2I/SPRIGHT)] [[Dataset](https://huggingface.co/datasets/SPRIGHT-T2I/spright)]



<!-- omit in toc -->
# Papers

<!-- omit in toc -->
## üî• Text-Guided Image Inpainting
- <span id="text-year-2024">**Year 2024**</span>
  - **ICLR**
    - ***MaGIC:*** Multi-modality Guided Image Completion [[Paper]](https://openreview.net/pdf?id=o7x0XVlCpX) [[Code]](https://github.com/yeates/MaGIC)
  - **arXiv**
    - Outline-Guided Object Inpainting with Diffusion Models [[Paper]](https://arxiv.org/pdf/2402.16421.pdf)
- <span id="text-year-2023">**Year 2023**</span> 


[<u><small><üéØBack to Top></small></u>](#contents)

<!-- omit in toc -->
## Vanilla Image Inpainting
- <span id="vanilla-year-2024">**Year 2024**</span> 
  - **CVPR**
    - ‚ö†Ô∏è Don't Look into the Dark: Latent Codes for Pluralistic Image Inpainting [Paper]

 [<u><small><üéØBack to Top></small></u>](#contents)

- <span id="vanilla-year-2023">**Year 2023**</span> 
  - **CVPRW**
    - Image Inpainting with Hypergraphs for Resolution Improvement in Scanning Acoustic Microscopy [[Paper]](https://openaccess.thecvf.com/content/CVPR2023W/DL-UIA/papers/Somani_Image_Inpainting_With_Hypergraphs_for_Resolution_Improvement_in_Scanning_Acoustic_CVPRW_2023_paper.pdf)
    - Internal Diverse Image Completion [[Paper]](https://openaccess.thecvf.com/content/CVPR2023W/GCV/papers/Alkobi_Internal_Diverse_Image_Completion_CVPRW_2023_paper.pdf) [[Code]](https://github.com/NoaAlkobi/IDC)


 [<u><small><üéØBack to Top></small></u>](#contents)

- <span id="vanilla-year-2022">**Year 2022**</span>

  - **NeurIPS**
    - Cross-Image Context for Single Image Inpainting [[Paper]](https://proceedings.neurips.cc/paper_files/paper/2022/file/09b6e009612875dd0a7291d5f4fd8b49-Paper-Conference.pdf)

 [<u><small><üéØBack to Top></small></u>](#contents)

- <span id="vanilla-year-2021">**Year 2021**</span>
  - **CVPR**
    - ***TransFill:*** Reference-Guided Image Inpainting by Merging Multiple Color and Spatial Transformations [[Paper]](https://openaccess.thecvf.com/content/CVPR2021/papers/Zhou_TransFill_Reference-Guided_Image_Inpainting_by_Merging_Multiple_Color_and_Spatial_CVPR_2021_paper.pdf) [[Code]](https://github.com/yzhouas/TransFill-Reference-Inpainting)
    - Image Inpainting With External-Internal Learning and Monochromic Bottleneck [[Paper]](https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Image_Inpainting_With_External-Internal_Learning_and_Monochromic_Bottleneck_CVPR_2021_paper.pdf) [[Code]](https://github.com/Tengfei-Wang/external-internal-inpainting)
    - Image Inpainting Guided by Coherence Priors of Semantics and Textures [[Paper]](https://openaccess.thecvf.com/content/CVPR2021/papers/Liao_Image_Inpainting_Guided_by_Coherence_Priors_of_Semantics_and_Textures_CVPR_2021_paper.pdf)
    - ***PD-GAN:*** Probabilistic Diverse GAN for Image Inpainting [[Paper]](https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_PD-GAN_Probabilistic_Diverse_GAN_for_Image_Inpainting_CVPR_2021_paper.pdf) [[Code]](https://github.com/KumapowerLIU/PD-GAN)
    - Generating Diverse Structure for Image Inpainting With Hierarchical VQ-VAE [[Paper]](https://openaccess.thecvf.com/content/CVPR2021/papers/Peng_Generating_Diverse_Structure_for_Image_Inpainting_With_Hierarchical_VQ-VAE_CVPR_2021_paper.pdf) [[Code]](https://github.com/USTC-JialunPeng/Diverse-Structure-Inpainting)
  - **ICCV**
    - Distillation-guided Image Inpainting [[Paper]](https://openaccess.thecvf.com/content/ICCV2021/papers/Suin_Distillation-Guided_Image_Inpainting_ICCV_2021_paper.pdf)


 [<u><small><üéØBack to Top></small></u>](#contents)

- <span id="vanilla-year-2020">**Year 2020**</span>
  - **CVPR**
    - ***UCTGAN:*** Diverse Image Inpainting Based on Unsupervised Cross-Space Translation [[Paper]](https://openaccess.thecvf.com/content_CVPR_2020/papers/Zhao_UCTGAN_Diverse_Image_Inpainting_Based_on_Unsupervised_Cross-Space_Translation_CVPR_2020_paper.pdf)
    - Contextual Residual Aggregation for Ultra High-Resolution Image Inpainting [[Paper]](https://openaccess.thecvf.com/content_CVPR_2020/papers/Yi_Contextual_Residual_Aggregation_for_Ultra_High-Resolution_Image_Inpainting_CVPR_2020_paper.pdf) [[Code]](https://github.com/Atlas200dk/sample-imageinpainting-HiFill)
    - ***RFR-Net:*** Recurrent Feature Reasoning for Image Inpainting [[Paper]](https://openaccess.thecvf.com/content_CVPR_2020/papers/Li_Recurrent_Feature_Reasoning_for_Image_Inpainting_CVPR_2020_paper.pdf) [[Code]](https://github.com/jingyuanli001/RFR-Inpainting)
    - Prior Guided GAN Based Semantic Inpainting [[Paper]](https://openaccess.thecvf.com/content_CVPR_2020/papers/Lahiri_Prior_Guided_GAN_Based_Semantic_Inpainting_CVPR_2020_paper.pdf)
    - Semantic Image Manipulation Using Scene Graph [[Paper]](https://openaccess.thecvf.com/content_CVPR_2020/papers/Dhamo_Semantic_Image_Manipulation_Using_Scene_Graphs_CVPR_2020_paper.pdf) [[Code]](https://github.com/he-dhamo/simsg)

 [<u><small><üéØBack to Top></small></u>](#contents)

- <span id="vanilla-year-2019">**Year 2019**</span>
  - **CVPR**
    - Learning Pyramid-Context Encoder Network for High-Quality Image Inpainting [[Paper]](https://openaccess.thecvf.com/content_CVPR_2019/papers/Zeng_Learning_Pyramid-Context_Encoder_Network_for_High-Quality_Image_Inpainting_CVPR_2019_paper.pdf) [[Code]](https://github.com/researchmm/PEN-Net-for-Inpainting)
    - Foreground-Aware Image Inpainting [[Paper]](https://openaccess.thecvf.com/content_CVPR_2019/papers/Xiong_Foreground-Aware_Image_Inpainting_CVPR_2019_paper.pdf)
    - ***PEPSI:*** Fast Image Inpainting With Parallel Decoding Network [[Paper]](https://openaccess.thecvf.com/content_CVPR_2019/papers/Sagong_PEPSI__Fast_Image_Inpainting_With_Parallel_Decoding_Network_CVPR_2019_paper.pdf) [[Code]](https://github.com/Forty-lock/PEPSI-Fast_image_inpainting_with_parallel_decoding_network)
    - Pluralistic Image Completion [[Paper]](https://openaccess.thecvf.com/content_CVPR_2019/papers/Zheng_Pluralistic_Image_Completion_CVPR_2019_paper.pdf) [[Code]](https://github.com/lyndonzheng/Pluralistic-Inpainting)

 [<u><small><üéØBack to Top></small></u>](#contents)

- <span id="vanilla-year-2018">**Year 2018**</span> 
  - **CVPR**
    - ***DeepFill-v1:*** Generative Image Inpainting With Contextual Attention [[Paper]](https://openaccess.thecvf.com/content_cvpr_2018/papers/Yu_Generative_Image_Inpainting_CVPR_2018_paper.pdf) [[Code]](https://github.com/JiahuiYu/generative_inpainting) [[Video]](https://www.youtube.com/watch?v=xz1ZvcdhgQ0&feature=youtu.be)
    - Disentangling Structure and Aesthetics for Style-Aware Image Completion [[Paper]](https://openaccess.thecvf.com/content_cvpr_2018/papers/Gilbert_Disentangling_Structure_and_CVPR_2018_paper.pdf)


 [<u><small><üéØBack to Top></small></u>](#contents)

- <span id="vanilla-year-2016">**Year 2016**</span>
  - **CVPR**
    - ***Context Encoders:*** Feature Learning by Inpainting [[Paper]](https://openaccess.thecvf.com/content_cvpr_2016/papers/Pathak_Context_Encoders_Feature_CVPR_2016_paper.pdf) [[Code]](https://github.com/BoyuanJiang/context_encoder_pytorch)

 [<u><small><üéØBack to Top></small></u>](#contents)

<!-- omit in toc -->
## Blind Image Inpainting
- <span id="blind-year-2023">**Year 2023**</span> 
  - **CVPRW**
    - Blind Image Inpainting via Omni-dimensional Gated Attention and Wavelet Queries [[Paper]](https://openaccess.thecvf.com/content/CVPR2023W/NTIRE/papers/Phutke_Blind_Image_Inpainting_via_Omni-Dimensional_Gated_Attention_and_Wavelet_Queries_CVPRW_2023_paper.pdf) [[Code]](https://github.com/shrutiphutke/Blind_Omni_Wav_Net)
  - **TMM**
    - ***FT-TDR:*** Frequency-Guided Transformer and Top-Down Refinement Network for Blind Face Inpainting [[Paper]](https://arxiv.org/pdf/2108.04424.pdf)
  - **TPAMI**
    - Self-Prior Guided Pixel Adversarial Networks for Blind Image Inpainting [[Paper]](https://ieeexplore.ieee.org/document/10147235)
- <span id="blind-year-2022">**Year 2022**</span> 
  - **ACM MM**
    - ***TransCNN-HAE:*** Transformer-CNN Hybrid AutoEncoder for Blind Image Inpainting [[Paper]](https://dl.acm.org/doi/abs/10.1145/3503161.3547848)
  - **IPTA**
    - ***ARIN:*** Adaptive Resampling and Instance Normalization for Robust Blind Inpainting of Dunhuang Cave Paintings [[Paper]](https://arxiv.org/pdf/2402.16188.pdf)
- <span id="blind-year-2020">**Year 2020**</span> 
  - **ECCV**
    - ***VCNet:*** A Robust Approach to Blind Image Inpainting [[Paper]](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123700749.pdf) [[Reproduced Code]](https://github.com/birdortyedi/vcnet-blind-image-inpainting)
  
[<u><small><üéØBack to Top></small></u>](#contents)

<!-- omit in toc -->
## Edge-Based Image Inpainting
- <span id="edge-year-2023">**Year 2023**</span> 
  - **TPAMI**
    - ***ZITS++:*** Image Inpainting by Improving the Incremental Transformer on Structural Priors [[Paper]](https://ieeexplore.ieee.org/document/10136788) [[Code]](https://github.com/DQiaole/ZITS_inpainting) [[Project]](https://dqiaole.github.io/ZITS_inpainting/)
- <span id="edge-year-2022">**Year 2022**</span> 
  - **CVPR**
    - ***ZITS:*** Incremental Transformer Structure Enhanced Image Inpainting with Masking Positional Encoding [[Paper]](https://openaccess.thecvf.com/content/CVPR2022/papers/Dong_Incremental_Transformer_Structure_Enhanced_Image_Inpainting_With_Masking_Positional_Encoding_CVPR_2022_paper.pdf) [[Code]](https://github.com/DQiaole/ZITS_inpainting) [[Project]](https://dqiaole.github.io/ZITS_inpainting/)
- <span id="edge-year-2021">**Year 2021**</span> 

    
[<u><small><üéØBack to Top></small></u>](#contents)

<!-- omit in toc -->
## Sketch-Guided Image Inpainting
- <span id="sketch-year-2023">**Year 2023**</span> 
  - **ACM MM**
    - ***Draw2Edit:*** Mask-Free Sketch-Guided Image Manipulation [[Paper]](https://dl.acm.org/doi/10.1145/3581783.3612398) [[Code]](https://github.com/YiwenXu/Draw2Edit)
- <span id="sketch-year-2022">**Year 2022**</span> 
  - **CVPR**
    - ***SketchEdit:*** Mask-Free Local Image Manipulation with Partial Sketches [[Paper]](https://openaccess.thecvf.com/content/CVPR2022/papers/Zeng_SketchEdit_Mask-Free_Local_Image_Manipulation_With_Partial_Sketches_CVPR_2022_paper.pdf) [[Code]](https://github.com/zengxianyu/sketchedit) [[Project]](http://zengyu.me/sketchedit/)
- <span id="sketch-year-2021">**Year 2021**</span> 


[<u><small><üéØBack to Top></small></u>](#contents)

<!-- omit in toc -->
## Face Image Inpainting
- <span id="face-year-2024">**Year 2024**</span>
 

[<u><small><üéØBack to Top></small></u>](#contents)

<!-- omit in toc -->
## Fashion Image Inpainting
- <span id="fashion-year-2024">**Year 2024**</span> 
    - ‚ö†Ô∏è ***TexFit:*** Text-Driven Fashion Image Editing with Diffusion Models [Paper]
- <span id="fashion-year-2019">**Year 2019**</span> 
  - **TIP**
    - Deep Portrait Image Completion and Extrapolation [[Paper]](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8866746)
  - **ICCV**
    - ***FiNet:*** Compatible and Diverse Fashion Image Inpainting [[Paper]](https://openaccess.thecvf.com/content_ICCV_2019/papers/Han_FiNet_Compatible_and_Diverse_Fashion_Image_Inpainting_ICCV_2019_paper.pdf) [[Code]](https://github.com/Skype-line/FiNet-pytorch)

[<u><small><üéØBack to Top></small></u>](#contents)

<!-- omit in toc -->
## Conventional Methods
- <span id="conventional-year-2020">**Year 2020**</span>
  - **TIP**
    - Image Inpainting Using Nonlocal Texture Matching and Nonlinear Filtering [[Paper]](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8531678)
    - Truncated Low-Rank and Total p Variation Constrained Color Image Completion and its Moreau Approximation Algorithm [[Paper]](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9141413)
- <span id="conventional-year-2019">**Year 2019**</span>
    - Multiple Pyramids Based Image Inpainting Using Local Patch Statistics and Steering Kernel Feature [[Paper]](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8733204)
- <span id="conventional-year-2018">**Year 2018**</span>
  - **TIP**
    - A Group-Based Image Inpainting Using Patch Refinement in MRF Framework [[Paper]](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8089766)
- <span id="conventional-year-2016">**Year 2016**</span>
  - **CVPR**
    - Multiview Image Completion with Space Structure Propagation [[Paper]](https://openaccess.thecvf.com/content_cvpr_2016/papers/Baek_Multiview_Image_Completion_CVPR_2016_paper.pdf)
 
[<u><small><üéØBack to Top></small></u>](#contents)

<!-- omit in toc -->
# Survey Papers
- [IJCV 2024] Deep Learning-based Image and Video Inpainting: A Survey [[Paper]](https://arxiv.org/pdf/2401.03395.pdf)
- [Pattern Recognit. 2023] Deep Learning for Image Inpainting: A Survey [[Paper]](https://www.sciencedirect.com/science/article/abs/pii/S003132032200526X)


[<u><small><üéØBack to Top></small></u>](#contents)

<!-- omit in toc -->
# Datasets
- ***Paris StreetView:*** Context Encoders: Feature Learning by Inpainting [[Paper]](https://openaccess.thecvf.com/content_cvpr_2016/papers/Pathak_Context_Encoders_Feature_CVPR_2016_paper.pdf) [[Code]](https://github.com/BoyuanJiang/context_encoder_pytorch) _(Since Google's terms of service has forbidden anyone from creating repositories of streetview data, the dataset is currently not available.)_

[<u><small><üéØBack to Top></small></u>](#contents)


<!-- omit in toc -->
# Q&A
- **Q: The conference sequence of this paper list?**
  - This paper list is organized according to the following sequence:
    - Conferences
      - CVPR
      - CVPRW
      - ICCV
      - ICCVW
      - ECCV
      - AAAI
      - IJCAI
      - WACV
      - NeurIPS
      - ICLR
      - ACM MM
      - SIGGRAPH
      - IPTA
    - Journals
      - TMM
      - TIP
      - TPAMI
      - TCSVT
    - arXiv

[<u><small><üéØBack to Top></small></u>](#contents)


<!-- omit in toc -->
# References

The `reference.bib` file summarizes bibtex references of up-to-date image inpainting papers, widely used datasets, and toolkits.
Based on the original references, I have made the following modifications to make their results look nice in the `LaTeX` manuscripts:
- Refereces are normally constructed in the form of `author-etal-year-nickname`. Particularly, references of datasets and toolkits are directly constructed as `nickname`, e.g., `imagenet`.
- In each reference, all names of conferences/journals are converted into abbreviations, e.g., `Computer Vision and Pattern Recognition -> CVPR`.
- The `url`, `doi`, `publisher`, `organization`, `editor`, `series` in all references are removed.
- The `pages` of all references are added if they are missing.
- All paper names are in title case. Besides, I have added an additional `{}` to make sure that the title case would also work well in some particular templates. 

If you have other demands of reference formats, you may refer to the original references of papers by searching their names in [DBLP](https://dblp.org/) or [Google Scholar](https://scholar.google.com/).

[<u><small><üéØBack to Top></small></u>](#contents)

<!-- omit in toc -->
# Star History

<p align="center">
    <a href="https://api.star-history.com/svg?repos=AlonzoLeeeooo/awesome-image-inpainting-studies&type=Date" target="_blank">
        <img width="500" src="https://api.star-history.com/svg?repos=AlonzoLeeeooo/awesome-image-inpainting-studies&type=Date" alt="Star History Chart">
    </a>
<p>

[<u><small><üéØBack to Top></small></u>](#contents)
