<p align="center">
  <h1 align="center">A Portal of Awesome Methods in Visual Tasks</h1>

A collection of projects on low/high level vision tasks, AIGC, Basic architecture, etc. 

If you have any suggestions about this repository, please feel free to [start a new issue](https://github.com/House-yuyu/A-Portal-of-Awesome-Methods-in-Visual-Tasks/issues/new) or [pull requests](https://github.com/House-yuyu/A-Portal-of-Awesome-Methods-in-Visual-Tasks/pulls).

<!-- omit in toc -->
# üî•News
- [Mar. 7th] **CVPR 2024, AAAI 2024, ICLR 2024 papers are updated.** Note that papers are not available currently are highlighted with "‚ö†Ô∏è". PDFs and references will be updated as soon as they are released.

<!-- omit in toc -->
# <span id="contents">Contents</span>
- [To-Do Lists](#to-do-lists)
- [Papers](#papers) _(Mainly Deep Learning-Based)_
  - [üî•Text-Guided Image Inpainting](#üî•-text-guided-image-inpainting)
    - [Year 2024](#text-year-2024)
  - [Vanilla Image Inpainting](#vanilla-image-inpainting)
    - [Year 2024](#vanilla-year-2024)
- [Datasets](#datasets)
- [Q&A](#qa)
- [References](#references)

<!-- omit in toc -->
# To-Do Lists
- Recent Papers
  - [x] Update CVPR 2024 Papers
  - [x] Update AAAI 2024 Papers
    - [ ] Update PDFs and References
  - [x] Update ICLR 2024 Papers
  - [ ] Update NeurIPS 2024 Papers
  - Regular Maintenance of Preprint arXiv Papers and Missed Papers
- Previous Papers
  - Published Papers on Conferences
    - [x] Update CVPR papers

[<u><small><üéØBack to Top></small></u>](#contents)


[<u><üéØBack to Top></u>](#head-content)

* <span id="head-si"> **Text-to-Imageü§î**  </span> 
    * (arXiv preprint 2024) [üí¨ Gender Bias Alignment] **PopAlign: Population-Level Alignment for Fair Text-to-Image Generation**, Shufan Li et al.  [[Paper](https://arxiv.org/abs/2406.19668)] [[Code](https://github.com/jacklishufan/PopAlignSDXL)]
    * (arXiv preprint 2024) [üí¨ Fine-Grained Feedback] **Beyond Thumbs Up/Down: Untangling Challenges of Fine-Grained Feedback for Text-to-Image Generation**, Katherine M. Collins et al.  [[Paper](https://arxiv.org/abs/2406.16807)] 
    * (CVPR 2024-Best Paper) [üí¨ Human Feedback] **Rich Human Feedback for Text-to-Image Generation**, Youwei Liang et al.  [[Paper](https://arxiv.org/abs/2312.10240)] 
    * (ICLR 2024) [üí¨ Unauthorized Data] **DIAGNOSIS: Detecting Unauthorized Data Usages in Text-to-image Diffusion Models**, Zhenting Wang et al.  [[Paper](https://openreview.net/pdf?id=f8S3aLm0Vp)] [[Code](https://github.com/ZhentingWang/DIAGNOSIS)]
    * (CVPR 2024) [üí¨ Open-set Bias Detection] **OpenBias: Open-set Bias Detection in Text-to-Image Generative Models**, Moreno D'Inc√† et al.  [[Paper](https://arxiv.org/abs/2404.07990)] 
    * (arXiv preprint 2024) [üí¨ Spatial Consistency] **Getting it Right: Improving Spatial Consistency in Text-to-Image Models**, Agneet Chatterjee et al.  [[Paper](https://arxiv.org/abs/2404.01197)] [[Project](https://spright-t2i.github.io/)] [[Code](https://github.com/SPRIGHT-T2I/SPRIGHT)] [[Dataset](https://huggingface.co/datasets/SPRIGHT-T2I/spright)]



<!-- omit in toc -->
# Papers

<!-- omit in toc -->
## üî• Text-Guided Image Inpainting
- <span id="text-year-2024">**Year 2024**</span>
  - **ICLR**
    - ***MaGIC:*** Multi-modality Guided Image Completion [[Paper]](https://openreview.net/pdf?id=o7x0XVlCpX) [[Code]](https://github.com/yeates/MaGIC)
  - **arXiv**
    - Outline-Guided Object Inpainting with Diffusion Models [[Paper]](https://arxiv.org/pdf/2402.16421.pdf)
- <span id="text-year-2023">**Year 2023**</span> 


[<u><small><üéØBack to Top></small></u>](#contents)

<!-- omit in toc -->
## Vanilla Image Inpainting
- <span id="vanilla-year-2024">**Year 2024**</span> 
  - **CVPR**
    - ‚ö†Ô∏è Don't Look into the Dark: Latent Codes for Pluralistic Image Inpainting [Paper]

 

[<u><small><üéØBack to Top></small></u>](#contents)


<!-- omit in toc -->
# Q&A
- **Q: The conference sequence of this paper list?**
  - This paper list is organized according to the following sequence:
    - Conferences
      - CVPR
      - CVPRW
      - ICCV
      - ICCVW
      - ECCV
      - AAAI
      - IJCAI
      - WACV
      - NeurIPS
      - ICLR
      - ACM MM
      - SIGGRAPH
      - IPTA
    - Journals
      - TMM
      - TIP
      - TPAMI
      - TCSVT
    - arXiv

[<u><small><üéØBack to Top></small></u>](#contents)


<!-- omit in toc -->

# References

The `reference.bib` file summarizes bibtex references of up-to-date image inpainting papers, widely used datasets, and toolkits.
Based on the original references, I have made the following modifications to make their results look nice in the `LaTeX` manuscripts:
- Refereces are normally constructed in the form of `author-etal-year-nickname`. Particularly, references of datasets and toolkits are directly constructed as `nickname`, e.g., `imagenet`.
- In each reference, all names of conferences/journals are converted into abbreviations, e.g., `Computer Vision and Pattern Recognition -> CVPR`.
- The `url`, `doi`, `publisher`, `organization`, `editor`, `series` in all references are removed.
- The `pages` of all references are added if they are missing.
- All paper names are in title case. Besides, I have added an additional `{}` to make sure that the title case would also work well in some particular templates. 

If you have other demands of reference formats, you may refer to the original references of papers by searching their names in [DBLP](https://dblp.org/) or [Google Scholar](https://scholar.google.com/).

[<u><small><üéØBack to Top></small></u>](#contents)

<!-- omit in toc -->

# Star History

<p align="center">
    <a href="https://api.star-history.com/svg?repos=House-yuyu/A-Portal-of-Awesome-Methods-in-Visual-Tasks&type=Date" target="_blank">
        <img width="500" src="https://api.star-history.com/svg?repos=House-yuyu/A-Portal-of-Awesome-Methods-in-Visual-Tasks&type=Date" alt="Star History Chart">
    </a>
<p>

